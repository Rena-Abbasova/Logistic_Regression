{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Features\n",
        "\n",
        "● enrollee_id : Unique ID for candidate\n",
        "\n",
        "● city: City code\n",
        "\n",
        "● city_ development _index : Developement index of the city (scaled)\n",
        "\n",
        "● gender: Gender of candidate\n",
        "\n",
        "● relevent_experience: Relevant experience of candidate\n",
        "\n",
        "● enrolled_university: Type of University course enrolled if any\n",
        "\n",
        "● education_level: Education level of candidate\n",
        "\n",
        "● major_discipline :Education major discipline of candidate\n",
        "\n",
        "● experience: Candidate total experience in years\n",
        "\n",
        "● company_size: No of employees in current employer's company\n",
        "\n",
        "● company_type : Type of current employer\n",
        "\n",
        "● last_new_job: Difference in years between previous job and current job\n",
        "\n",
        "● training_hours: training hours completed\n",
        "\n",
        "● target: 0 – Not looking for job change, 1 – Looking for a job change"
      ],
      "metadata": {
        "id": "mYgTo6a1JKIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "YvuYqGqpJbS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DS_Job_Change_Data.csv')"
      ],
      "metadata": {
        "id": "UsWB7F_jJu8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "mQ_j00iZJ3RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=data.copy()"
      ],
      "metadata": {
        "id": "ghH3oWUkVSJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BKR0W9M5TE1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the columns\n",
        "\n",
        "df=df.rename(columns= {'enrollee_id':'id','relevent_experience':'rel_exp', 'enrolled_university':'enr_univ','education_level':'ed_lev', 'major_discipline':'maj_dis','experience':'exp','company_size':'csize','company_type':'ctype','last_new_job':'lnjob','training_hours':'train_hour','city_development_index':'index'})\n",
        "\n"
      ],
      "metadata": {
        "id": "_cJS0lqoPCeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "xXNSXPAVQ1kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting and cleaning the data"
      ],
      "metadata": {
        "id": "LUzp2SVFKW6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # most of the data object"
      ],
      "metadata": {
        "id": "Bop7kWdywnbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspection(dataframe):\n",
        "  print('Tipe of variables we are working with')\n",
        "  print(dataframe.dtypes)\n",
        "\n",
        "  print('total samples with missing values:')\n",
        "\n",
        "  print(df.isnull().any(axis=1).sum())\n",
        "\n",
        "  print('Total missing values per Variables')\n",
        "  print(df.isnull().sum())\n",
        "  print('Map of missing values')\n",
        "  sns.heatmap(dataframe.isnull())\n"
      ],
      "metadata": {
        "id": "jD2_jlm8KeTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspection(df)"
      ],
      "metadata": {
        "id": "pddt5EBrLu5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there is lots of missing values\n",
        "# Drop small numbers of missing values in the columns: 'enr_univ', 'ed_lev', 'exp', 'lnjob'\n",
        "df.dropna(subset=['enr_univ', 'ed_lev', 'exp', 'lnjob'], inplace=True)"
      ],
      "metadata": {
        "id": "Q0R2CQiTxKPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rest of missing values we will imput with mode\n",
        "df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
        "\n",
        "df['maj_dis'].fillna(df['maj_dis'].mode()[0], inplace=True)\n",
        "\n",
        "df['ctype'].fillna(df['ctype'].mode()[0], inplace=True)\n",
        "\n",
        "df['csize'].fillna(df['csize'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "RWkRnPLIxpjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "XZ8BG4SmL6i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ZDjlPS9mTcia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "fdKqCxODYbgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "wm_8OxcluEK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.gender.unique()"
      ],
      "metadata": {
        "id": "xyoO08jrwQWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enoding categorical variables"
      ],
      "metadata": {
        "id": "eTHqnRsczJJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n"
      ],
      "metadata": {
        "id": "vNotnVSMzYxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_categories(df,variables):\n",
        "  ord_enc=OrdinalEncoder()\n",
        "  for i in variables:\n",
        "    name=i+'_code'\n",
        "    df[name]=ord_enc.fit_transform(df[[i]])\n",
        "    print('The encoded values for ' + i + ' are:')\n",
        "    print(df[name].unique())\n"
      ],
      "metadata": {
        "id": "spTe6IomzPkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_categories(df,['city', 'rel_exp','enr_univ', 'ed_lev',\n",
        "       'maj_dis', 'exp','ctype', 'lnjob','gender'])"
      ],
      "metadata": {
        "id": "ZhRC7_J90S1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qmKD_Qp90UFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Ph6PNJJh1ytG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization\n"
      ],
      "metadata": {
        "id": "qtrU4y6g9dam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_scatterplot (df, col_to_exclude, class_col):\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference(col_to_exclude)]\n",
        "  for col in X.columns.difference([class_col]):\n",
        "    g=sns.FacetGrid(df)\n",
        "    g.map(sns.scatterplot,col,class_col)\n"
      ],
      "metadata": {
        "id": "3VJy93oj9fxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_scatterplot(df,['id'],'target')"
      ],
      "metadata": {
        "id": "pjphNGTs-27K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_diagnostic (df, class_col, col_to_exclude):\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference([col_to_exclude])]\n",
        "  X=X[X.columns.difference([class_col])]\n",
        "  sns.pairplot(df,hue=class_col)"
      ],
      "metadata": {
        "id": "BF764Edy_BZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full_diagnostic(df,class_col='target',col_to_exclude='id')"
      ],
      "metadata": {
        "id": "zM5mhXc1NW2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression"
      ],
      "metadata": {
        "id": "u6mkydY6DQQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "hqu4Qt5KDYSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression (df, class_col, col_to_exclude):\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference([class_col])]\n",
        "  X=X[X.columns.difference(col_to_exclude)]\n",
        "\n",
        "  # Scalling variables\n",
        "\n",
        "  scaler=preprocessing.StandardScaler()\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "  y = df[class_col]\n",
        "  logit_model=sm.Logit(y,X)\n",
        "  result=logit_model.fit()\n",
        "  print(result.summary2())\n"
      ],
      "metadata": {
        "id": "yb8Og9oYAlpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logistic_regression(df,class_col='target',col_to_exclude=['id','train_hour','city_code'])"
      ],
      "metadata": {
        "id": "Nb3VvfIcRa1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seems like train_hours and city_code not significant values we can remove those values"
      ],
      "metadata": {
        "id": "Niop1xLhU1ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xmhyfw-9Xx5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coeff represent for one unit for variation in variable how much the log of the odds of Churning or not, changed."
      ],
      "metadata": {
        "id": "Z87RnUoZNaeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "5VQGlX9eNaTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math.exp(-0.1195) # an aditional age increases the odds of churn by 0.88"
      ],
      "metadata": {
        "id": "BCJOBvP-NZsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the ML Model"
      ],
      "metadata": {
        "id": "roz_xpKeYcUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from sklearn import config_context\n"
      ],
      "metadata": {
        "id": "vxDorXqwYkg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model(df, class_col, col_to_exclude):\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference([class_col])]\n",
        "  X=X[X.columns.difference(col_to_exclude)]\n",
        "\n",
        "  y=df[class_col]\n",
        "  global X_train,X_test,y_train,y_test # this allow us to call these variables outside this function\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "-98r7d91jZLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(X_train,X_test,y_train,y_test):\n",
        "  global logreg # define the logistic model as global model that can be used outside of this function\n",
        "  # fitting the logistic regression\n",
        "  logreg = LogisticRegression(random_state=13)\n",
        "  logreg.fit(X_train,y_train)\n",
        "  # predicting y values\n",
        "  global y_pred # define y_pred as aglobal variable that can be used ouside of this function\n",
        "  y_pred=logreg.predict(X_test)\n",
        "  logit_roc_auc=roc_auc_score(y_test,logreg.predict(X_test))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print('The area unedr the curve is: %0.2f'%logit_roc_auc)\n",
        "\n"
      ],
      "metadata": {
        "id": "wSHLMHRIZn22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prepare_model(df,class_col='target',col_to_exclude=['id','train_hour','city_code'])\n",
        "\n",
        "#prepare_model(df,class_col='target',col_to_exclude=[])\n"
      ],
      "metadata": {
        "id": "r_9ofaeCd3Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "4CIlGTmecgqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix\n",
        "\n",
        "def print_confusion_matrix(y_test, y_pred):\n",
        "    cm = sklearn_confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print('TN:%0.2f' % tn)\n",
        "    print('TP:%0.2f' % tp)\n",
        "    print('FN:%0.2f' % fn)\n",
        "    print('FP:%0.2f' % fp)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "PnR5_lhuemVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_roc_curve(logreg, X_test, y_test):\n",
        "    # Calculate predicted probabilities\n",
        "    y_pred_proba = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "    # Calculate AUC score\n",
        "    logit_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure()\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.plot([0, 1], [0, 1], 'b--')\n",
        "    plt.plot(fpr, tpr, color='darkorange', label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hT2ufEPCf2iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_roc_curve(logreg, X_test, y_test)"
      ],
      "metadata": {
        "id": "f_BW2iF1f2fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There is not a good model"
      ],
      "metadata": {
        "id": "QdK1lfRof2dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Imbalancee Class"
      ],
      "metadata": {
        "id": "6PyVXXCKkMdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].describe()"
      ],
      "metadata": {
        "id": "pomQBtmzf2aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter turning to balance the data using '\"class_weight='balanced\"'"
      ],
      "metadata": {
        "id": "dwnCC8sbf2W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class imbalance method 1\n",
        "def run_model_bweights(X_train,X_test,y_train,y_test):\n",
        "  global logreg # define the logistic model as global model that can be used outside of this function\n",
        "  # fitting the logistic regression\n",
        "  logreg = LogisticRegression(random_state=13, class_weight='balanced')\n",
        "  logreg.fit(X_train,y_train)\n",
        "  # predicting y values\n",
        "  global y_pred # define y_pred as aglobal variable that can be used ouside of this function\n",
        "  y_pred=logreg.predict(X_test)\n",
        "  logit_roc_auc=roc_auc_score(y_test,logreg.predict(X_test))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print('The area unedr the curve is: %0.2f'%logit_roc_auc)"
      ],
      "metadata": {
        "id": "y3SwBZPLf2Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model_bweights(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "SA8smtTHlYNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class imbalance method 2\n",
        "def run_model_aweights(X_train,X_test,y_train,y_test,w):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import roc_auc_score,classification_report\n",
        "    global logreg\n",
        "    logreg = LogisticRegression(random_state = 13,class_weight=w) # define class_weight parameter\n",
        "    logreg.fit(X_train, y_train) # fit the model\n",
        "    global y_pred\n",
        "    y_pred = logreg.predict(X_test) # predict on test data\n",
        "    logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))  # ROC AUC score\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"The area under the curve is: %0.2f\"%logit_roc_auc)  # AUC curve"
      ],
      "metadata": {
        "id": "Ee_QChtnygC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model_aweights(X_train,X_test,y_train,y_test,{0:90, 1:10})"
      ],
      "metadata": {
        "id": "0CRIsTo6ylC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also we can resample our dataset"
      ],
      "metadata": {
        "id": "mvqZFYSKmnRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "cxsuq0VGp5q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class imbalance method 3\n",
        "def adjust_imbalance(X_train,y_train,class_col):\n",
        "  X = pd.concat([X_train,y_train],axis=1)\n",
        "\n",
        "#separate the 2 clases\n",
        "  class0=X[X[class_col]==0]\n",
        "  class1=X[X[class_col]==1]\n",
        "\n",
        "# case 1 - bootstraps from the minority class\n",
        "\n",
        "  if len(class1)<len(class0):\n",
        "    resampled=resample(class1,replace=True,n_samples=len(class0),random_state=10)\n",
        "\n",
        "    resampled_df = pd.concat([resampled,class0])\n",
        "\n",
        "# case 1 - Resample from the majority class\n",
        "\n",
        "  else:\n",
        "    resampled = resample(class1,replace=False,n_samples=len(class0),random_state=10)\n",
        "    resampled_df = df.concat([resampled,class0])\n",
        "  return resampled_df\n"
      ],
      "metadata": {
        "id": "LL3NsW9pmQuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_df = adjust_imbalance(X_train,y_train,class_col = 'target')"
      ],
      "metadata": {
        "id": "WlXG5LADoqhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_model(resampled_df,class_col='target',col_to_exclude=['id','train_hour','city_code'])"
      ],
      "metadata": {
        "id": "ZJNpNjKmoqeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "stS8A6RDoqas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smoote approach"
      ],
      "metadata": {
        "id": "CBAgOfW8oqXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "TK-Mb7iTr92S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model_smoote(df, class_col, col_to_exclude):\n",
        "  # Synthetic Minority Oversampling approach . Generate new instances from existing minority casdes that you supply as input\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference([class_col])]\n",
        "  X=X[X.columns.difference(col_to_exclude)]\n",
        "\n",
        "  y=df[class_col]\n",
        "  global X_train,X_test,y_train,y_test # this allow us to call these variables outside this function\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
        "  sm = SMOTE(random_state=0)\n",
        "  X_train,y_train = sm.fit_resample(X_train,y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L9kmM2sxoqT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_model_smoote(df,class_col='target',col_to_exclude=['id','train_hour','city_code'])"
      ],
      "metadata": {
        "id": "s2DpHvjioqQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(X_train,X_test,y_train,y_test)\n"
      ],
      "metadata": {
        "id": "1qe1m-e4s18M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection"
      ],
      "metadata": {
        "id": "-6K9tDq37Itf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_col = 'target'\n",
        "cols_to_exclude=['id']\n",
        "\n",
        "# function for feature selection\n",
        "def var_threshold_selection(df,cols_to_exclude,class_col,threshold):\n",
        "  from sklearn.feature_selection import VarianceThreshold\n",
        "  import numpy as np\n",
        "  from sklearn import preprocessing\n",
        "\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist() #finding all the numerical columns from the dataframe\n",
        "  X=df[cols] #creating a dataframe only with the numerical columns\n",
        "  X = X[X.columns.difference(cols_to_exclude)] #columns to exclude\n",
        "  X = X[X.columns.difference([class_col])]\n",
        "  ## Scaling variables\n",
        "  scaler = preprocessing.StandardScaler().fit(X)\n",
        "  X_scaled = scaler.transform(X)\n",
        "  var_thr = VarianceThreshold(threshold = threshold) #Removing both constant and quasi-constant\n",
        "  var_thr.fit(X_scaled)\n",
        "  var_thr.get_support()\n",
        "\n",
        "  global selected_cols\n",
        "  selected_cols = X.columns[var_thr.get_support()]\n",
        "\n",
        "  print(\"The selected features are: \")\n",
        "  print(list(selected_cols))"
      ],
      "metadata": {
        "id": "Hjxb2ZkH7H57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_threshold_selection(df,cols_to_exclude=['id'],class_col = 'target',threshold=1)"
      ],
      "metadata": {
        "id": "G0IXevzu7Qkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_model(resampled_df,class_col='target',col_to_exclude=['id','train_hour',\n",
        "                                                              'maj_dis_code', 'exp_code', 'ctype_code',\n",
        "                                                              'lnjob_code','rel_exp_code', 'enr_univ_code'])"
      ],
      "metadata": {
        "id": "WAOtHmbU-BKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "rB4RcITe-brF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RFE for feature selection\n",
        "def rfe_selection(df,cols_to_exclude,class_col,model):\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  import numpy as np\n",
        "  from sklearn.feature_selection import RFE\n",
        "\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist() #finding all the numerical columns from the dataframe\n",
        "  X=df[cols] #creating a dataframe only with the numerical columns\n",
        "  X = X[X.columns.difference(cols_to_exclude)] #columns to exclude\n",
        "  X = X[X.columns.difference([class_col])]\n",
        "  y = df[class_col]\n",
        "\n",
        "  rfe = RFE(model)\n",
        "  rfe = rfe.fit(X, y) # fit the model\n",
        "  global selected_cols\n",
        "  selected_cols = X.columns[rfe.support_]\n",
        "\n",
        "  print(\"The selected features are: \")\n",
        "  print(list(selected_cols))"
      ],
      "metadata": {
        "id": "ahLGSj-m7bor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfe_selection(df,class_col = 'target',cols_to_exclude=['id'],model=logreg)"
      ],
      "metadata": {
        "id": "nhENB1eX7gEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_model(resampled_df,class_col = 'target',col_to_exclude=['id','index', 'train_hour', 'city_code',\n",
        "                                                                 'maj_dis_code','exp_code','ctype_code', 'lnjob_code'])\n",
        "\n",
        "run_model(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "do37-Bc-7h3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numeric columns\n",
        "numeric_columns = df.select_dtypes(include='number').columns\n",
        "\n",
        "numeric_columns\n"
      ],
      "metadata": {
        "id": "Y20g07q27hYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving & Running the Model"
      ],
      "metadata": {
        "id": "rPJbREdYzmwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model using pickle function\n",
        "import pickle\n",
        "pickle.dump(logreg, open('model1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "yiSiuqaOzpSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "model = pickle.load(open('model1.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "hwKgUsZtztOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on the test data\n",
        "model.predict(X_test)"
      ],
      "metadata": {
        "id": "Qm0BROpAzzbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision tree"
      ],
      "metadata": {
        "id": "4AhtxR3ZNflH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "CwvPCKTlNwAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model_smoote(df, class_col, col_to_exclude):\n",
        "  # Synthetic Minority Oversampling approach . Generate new instances from existing minority casdes that you supply as input\n",
        "  cols=df.select_dtypes(include=np.number).columns.tolist()\n",
        "  X=df[cols]\n",
        "  X=X[X.columns.difference([class_col])]\n",
        "  X=X[X.columns.difference(col_to_exclude)]\n",
        "\n",
        "  y=df[class_col]\n",
        "  global X_train,X_test,y_train,y_test # this allow us to call these variables outside this function\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
        "  sm = SMOTE(random_state=0)\n",
        "  X_train,y_train = sm.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "hHFhDu_oOsZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_model_smoote(df,class_col='target',col_to_exclude=['id','train_hour','city_code'])"
      ],
      "metadata": {
        "id": "JIsGs-rwO2II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(X_train,X_test,y_train,y_test):\n",
        "  global dectree# define the logistic model as global model that can be used outside of this function\n",
        "  # fitting the logistic regression\n",
        "  dectree = DecisionTreeClassifier(random_state=13,criterion='entropy')\n",
        "  dectree.fit(X_train,y_train)\n",
        "  # predicting y values\n",
        "  global y_pred # define y_pred as aglobal variable that can be used ouside of this function\n",
        "  y_pred=dectree.predict(X_test)\n",
        "  dectree_roc_auc=roc_auc_score(y_test,dectree.predict(X_test))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print('The area unedr the curve is: %0.2f'%dectree_roc_auc)"
      ],
      "metadata": {
        "id": "7jo5Pq6tNfPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "id": "c9k_dhmGPHAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(dectree, X_test, y_test):\n",
        "    # Calculate predicted probabilities\n",
        "    y_pred_proba = dectree.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "    # Calculate AUC score\n",
        "    dectree_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure()\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.plot([0, 1], [0, 1], 'b--')\n",
        "    plt.plot(fpr, tpr, color='darkorange', label='Decision tree (area = %0.2f)' % dectree_roc_auc)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7r7HF4sfQgUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curve(dectree,X_test,y_test)"
      ],
      "metadata": {
        "id": "S7Au5-FCPHiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix\n",
        "\n",
        "def print_confusion_matrix(y_test, y_pred):\n",
        "    cm = sklearn_confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print('TN:%0.2f' % tn)\n",
        "    print('TP:%0.2f' % tp)\n",
        "    print('FN:%0.2f' % fn)\n",
        "    print('FP:%0.2f' % fp)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "K0kyZZ-ZRIXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing decision tree"
      ],
      "metadata": {
        "id": "9YFB5n6PWdCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree"
      ],
      "metadata": {
        "id": "PgZlXLqKURQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "def plot_model(model, class_names, max_depth=None, figsize=(20,20), fontsize=1):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plot_tree(model,\n",
        "              feature_names=model.feature_names_in_,\n",
        "              class_names=class_names,\n",
        "              fontsize=fontsize,\n",
        "              max_depth=max_depth,\n",
        "              filled=True)\n",
        "    plt.show()\n",
        "\n",
        "plot_model(dectree, 'target')\n"
      ],
      "metadata": {
        "id": "iw_kYSGHTymE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(dectree, 'target', max_depth=2,figsize=(20,20),fontsize=10)"
      ],
      "metadata": {
        "id": "h_tv0VQsU87D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importances(model):\n",
        "  feature_importances = pd.Series(model.feature_importances_, index=model.feature_names_in_)\n",
        "  feature_importances = feature_importances.sort_values(axis=0, ascending=False)\n",
        "  fig, ax = plt.subplots()\n",
        "  feature_importances.plot.bar()\n",
        "  ax.set_title(\"Feature importances\")\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "qnD9Na31VIp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_feature_importances(dectree)"
      ],
      "metadata": {
        "id": "TLUO88NRVfVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qY0RBRNqWDFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}